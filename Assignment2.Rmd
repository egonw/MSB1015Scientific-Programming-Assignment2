---
title: "Assignment2"
author: "Raphael Stolpe"
date: "9/23/2019"
output: html_notebook
---
# Introduction
The assignment is to query wikidata for information about the chemical class alkanes. Therefore, it is necessary to design a query that will search for alkanes in bespoken database and retrieve data which is needed for further analysis. This information includes boilingpoint, chemical smiles to infer structural information as well as corresponding units and names. 
Subsqequently, the assignment is to build a model that can predict the boilingpoint of a chemical compound based on its chemical composition. In other words the assignment is to derive physical properties from a compounds chemical structure. Therefore, chemical features such as wiener paramters [1] and atom count are used to build a regression model. 
It is assessed how good the model can predict the boilingpoint. 
```{r setup, include=FALSE}
## 0. Install and load packages
# Please run this code section to ensure all necessary packages are installed. Also make sure that the function files below are in the same directory as this file before executing.
packages <- c("rcdk", "WikidataQueryServiceR", "Metrics", "pls", "graphics", "e1071")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
library(rcdk)
library(WikidataQueryServiceR)
library(Metrics)
library(pls)
library(graphics)
library(e1071)
source("functions/Unit_conversion_to_Kelvin.R")
source("functions/computeDescriptors.R")
source("functions/removeConstantDesc.R")
```
# Methods
## Query
The query on wikidata using the WikidataQueryServiceR [4] package returns all alkanes where the boilingpoint is available in wikidata. It returns the compound identifier, compound label, boilingpoint, boilingpoint unit as well as the boilingpoint unit label. 
All units are converted into kelvin because it is the SI unit. The result is inspected with respect to it's completeness and correctness of boilingpoints. Two boilingpoints were detected to have and comma instead of a point. Therefore, the two compounds had unreasonably high boilingpoints. After correcting for the mistake in wikidata, the data was found to be correct. 
```{r query}


# 1. Query for Alkanes in wikidata: get boilingpoint with units and smiles for each molecule
query <- 'SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnit ?bpUnitLabel ?CC WHERE {   
          ?comp wdt:P31/wdt:P279* wd:Q41581 ;   
          wdt:P233 ?CC ;     
          p:P2102 [         ps:P2102 ?bp ;           
          psv:P2102/wikibase:quantityUnit  ?bpUnit         ] .   
          SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". } } '
# Results of query as well as results after unit conversion are stored in QueryResults
QueryResults <- query_wikidata(query)
QueryResults <- Unit_conversion_to_Kelvin(QueryResults)
```
``` {r metrics, echo=FALSE}
print(paste("Mean boilingpoint:", round(mean(QueryResults$bp)),"K"))
print(paste("Lowest boilingpoint:", round(min(QueryResults$bp)),"K"))
print(paste("Highest boilingpoint:", round(max(QueryResults$bp)),"K"))
```
## Descriptors
The R package rcdk [2] was used to compute chemical compound descriptors based on smiles. As descriptors Wiener numbers [1], apolarity and atom count were chosen as descriptors. However the number of descriptors as well as the type of descriptors will be subject to change for future users. 
```{r descriptors}
# 2. Parse smiles and compute descriptors
# Selection of suitable selectors is crucial to be able to predict the boiling point of chemical
# compound with reasonable accuracy. The function get.desc.names() will print a list of descriptors
# available within the rcdk package. The user of this code may chose any set of descriptors that is
# considered to contain information relevant to predicting the boiling point. Adding it to the list
# of descriptor names will allow for computation of descriptors from the smiles. 
descriptorNames <- c(
  'org.openscience.cdk.qsar.descriptors.molecular.WienerNumbersDescriptor',
  'org.openscience.cdk.qsar.descriptors.molecular.APolDescriptor',
  'org.openscience.cdk.qsar.descriptors.molecular.AtomCountDescriptor',
  'org.openscience.cdk.qsar.descriptors.molecular.MDEDescriptor'
  )
descriptors <- computeDescriptors(QueryResults, descriptorNames)
descriptors <- removeConstantDesc(descriptors)
# For some reason descriptor MDEC.34 does not get removed although it is a constant clumn. 
# Therefore, it is necessary to track it down and remove it manually when using MDED descriptors. 
# Please comment the line below or adjust, if a different use of descriptors is intended.
descriptors <- descriptors[, - 14] 


```
Partial least squares regression (pls) [3] was chosen to perform regression from descriptors to boilingpoint. The dataset is split into training and testing dataset after randomization. pls regression is performed with crossvalidation. Root mean squared error of prediction and correlation of prediction with true results is chosen to assess the performance of the regression model. It is also being compared with the null model which is taking the average of all boilingpoints in the training set to predict the test set. 

Additionally, a support vector machine regression (package e1071, [5]) is performed in order to assess reproducibility of the results using a different method. 

# Results
When taking the four descriptors that are set by default, the RMSEP on the training set indicates that using two principle components will predict boilingpoints on the testset with reasonable accuracy. Plots and numbers report on the performance of the model. 
RMSE of prediction for the nullmodel created by plsr, the nullmodel created independently, pls regression and support vector machine regression are reported below. 
```{r pls regression}
# 3. Perform pls regression 

# 3.1 split dataset into training and testing datasets
# Randomization has great influence on how the model is built (trainingset) and how it performs on 
# the testset. Because the dataset is fairly small the way in which randomization occurs (set.seed())
# is esential fro reproducibility of results. It is important to keep in mind that a different seed 
# might produce different results. 
PredictorsWithResponse <- data.frame(QueryResults$bp, descriptors)
set.seed(42)
rows <- sample(nrow(PredictorsWithResponse))
PredictorsWithResponse <- PredictorsWithResponse[rows, ]
split <- round(nrow(PredictorsWithResponse)*0.7)

train <- PredictorsWithResponse[1:split, ]
test <- PredictorsWithResponse[(split+1):nrow(PredictorsWithResponse), ]
ytrain <- train$QueryResults.bp
ytest <- test$QueryResults.bp
```

```  {r report, echo =FALSE}
# report sizes of train and test 
print(paste("Number of samples in trainingset: ", nrow(train)))
print(paste("Number of samples in testset: ", nrow(test)))
```

``` {r model}
# 3.2 Build null model as the mean of all boilingpoints 
nullmodel <- mean(train$QueryResults.bp)
errorofNullmodel <- rmse(test$QueryResults.bp, nullmodel)

# 3.3 Train pls regression model
plsModel <- plsr(train$QueryResults.bp ~., data = train, validation = "CV")
errorPLSregression <- RMSEP(plsModel, estimate = "CV") # <- select two principle components
predictedbyPLS <- predict(plsModel, test)
RMSEPofPLSonTest <- rmse(predictedbyPLS, ytest)
#plot(mdl$residuals)
## Visualization
# plot predicted against actual values
plot(predictedbyPLS[,,1], ytest, xlab = "Predicted Boiling Point [K]", ylab = "Measured Boiling Point [K]", main = "Regression with one PC")
plot(predictedbyPLS[,,2], ytest, xlab = "Predicted Boiling Point [K]", ylab = "Measured Boiling Point [K]", main = "Regression with two PCs")
plot(predictedbyPLS[,,3], ytest, xlab = "Predicted Boiling Point [K]", ylab = "Measured Boiling Point [K]", main = "Regression with three PCs")
plot(predictedbyPLS[,,4], ytest, xlab = "Predicted Boiling Point [K]", ylab = "Measured Boiling Point [K]", main = "Regression with four PCs")

# plot error
# first error is the error of the null model and does not use any principle component from the pca.
# Thus it will be excluded from this plot. 
plot(errorPLSregression$val[,,2:ncol(data)], type = "l", pch = 16,  xlab = "Number of principle components",
     ylab = "RMSEP [K]", main = "RMSE of Prediction against Number of Principle Components")

# correlation of results 
correlationPredictedvActual <- c()
for (i in 1:ncol(PredictorsWithResponse)-1) {
  correlationPredictedvActual[i] <- cor(predictedbyPLS[,,i], ytest)
}
plot(correlationPredictedvActual, type = "p", xlab = "Number of principle components", 
     ylab = "Correlation",
     main = "Correlation of Prediction against Number of Principle Components")
# Build svm model for comparison
svmModel <- svm(train$QueryResults.bp ~., data = train)
svm.predicted <- predict(svmModel, test)
errorbySVM <- rmse(svm.predicted, ytest)
plot(svm.predicted, ytest, xlab = "Predicted Boiling Point [K]", ylab = "Measured Boiling Point [K]", main = "Regression using SVM")
correlationSVMprediction <- cor(svm.predicted, ytest)
```

``` {r, echo = FALSE}
print(paste("Error of the nullmodel built by plsr:", round(mean(errorPLSregression$val[,,1])),"K"))
print(paste("Error of the nullmodel:", round(errorofNullmodel), "K"))
print(paste("Error of pls regression using two PCs:", round(mean(errorPLSregression$val[,,3])),"K"))
print(paste("Error of the support vector machine regression:", round(errorbySVM), "K"))
print(paste("Correlation of predicted boilingoints using pls regression (2 PCs) with measured data:", round(correlationPredictedvActual[2], digits = 3)))
print(paste("Correlation of predicted boilingpoints using SVM regression with measured data:", round(correlationSVMprediction, digits = 3)))
```


# Discussion
The two nullmodels produce fairly similar results with a large error of over 200K. Thus it can be stated that the nullmodel in either case does not accurate predictions when the boilingpoints range from roughly 100K to 1000K. 
However, the pls model with two PCs and the SVM regression model produce very similar and more accurate results with an error of 49K and 46K, respectively. That indicates that the two specific models have a similar capability of learning from the data and predicting the boilingpoint. Two PCs where selected as model, because the error on the trainingset does not drop significantly when using more principle components. 
Correlation between predicted boilingpoints and measured boilingpoints is 0.969 and 0.982 for pls and svm, respectively. These numbers show that this result is reproducible. Furthermore, it shows that using few principle components prevents from overfitting to the data. 
It is important to keep in my mind that prediction accuracy and quality of the models are largely effected by the number and quality of predictors (i.e. chemical descriptors). Furthermore, it needs to be stressed that due to the fairly small size of the dataset, randomization can have a large effect on the quality of the models after splitting into trainingset and testingset. 

# References 

[1] Wiener, H. (1947). Structural Determination of Paraffin Boiling Points. Journal of the American Chemical Society, 69(1), 17–20. https://doi.org/10.1021/ja01193a005

[2] Guha, R. (2007). 'Chemical Informatics Functionality in R'. Journal of Statistical Software 6(18)

[3] Bjørn-Helge Mevik, Ron Wehrens and Kristian Hovde Liland (2019). pls: Partial Least
    Squares and Principal Component Regression. R package version 2.7-1.
    https://CRAN.R-project.org/package=pls

[4] Mikhail Popov (2017). WikidataQueryServiceR: API Client Library for 'Wikidata Query
  Service'. R package version 0.1.1.
  https://CRAN.R-project.org/package=WikidataQueryServiceR

[5] David Meyer, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel and
  Friedrich Leisch (2019). e1071: Misc Functions of the Department of
  Statistics, Probability Theory Group (Formerly: E1071), TU Wien. R
  package version 1.7-1. https://CRAN.R-project.org/package=e1071
